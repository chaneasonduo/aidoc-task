{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b93fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq pydantic langchain langchain_deepseek langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55645d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/4jwq1tp50x56pw2gms9_1rm80000gq/T/ipykernel_33980/2638776365.py:27: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  output = llm(_input.to_string())\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33m公司内部流程该如何优化？\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     26\u001b[39m _input = prompt.format_prompt(question=question)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m output = \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_input\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# LangChain 自动解析为 CategoryOutput 对象\u001b[39;00m\n\u001b[32m     30\u001b[39m parsed = parser.parse(output.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:190\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    189\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1252\u001b[39m, in \u001b[36mBaseChatModel.__call__\u001b[39m\u001b[34m(self, messages, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1230\u001b[39m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m0.1.7\u001b[39m\u001b[33m\"\u001b[39m, alternative=\u001b[33m\"\u001b[39m\u001b[33minvoke\u001b[39m\u001b[33m\"\u001b[39m, removal=\u001b[33m\"\u001b[39m\u001b[33m1.0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1231\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m   1232\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1236\u001b[39m     **kwargs: Any,\n\u001b[32m   1237\u001b[39m ) -> BaseMessage:\n\u001b[32m   1238\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model.\u001b[39;00m\n\u001b[32m   1239\u001b[39m \n\u001b[32m   1240\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1250\u001b[39m \u001b[33;03m        The model output message.\u001b[39;00m\n\u001b[32m   1251\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     generation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[32m   1256\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation.message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:807\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    792\u001b[39m inheritable_metadata = {\n\u001b[32m    793\u001b[39m     **(metadata \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    794\u001b[39m     **\u001b[38;5;28mself\u001b[39m._get_ls_params(stop=stop, **kwargs),\n\u001b[32m    795\u001b[39m }\n\u001b[32m    797\u001b[39m callback_manager = CallbackManager.configure(\n\u001b[32m    798\u001b[39m     callbacks,\n\u001b[32m    799\u001b[39m     \u001b[38;5;28mself\u001b[39m.callbacks,\n\u001b[32m   (...)\u001b[39m\u001b[32m    804\u001b[39m     \u001b[38;5;28mself\u001b[39m.metadata,\n\u001b[32m    805\u001b[39m )\n\u001b[32m    806\u001b[39m messages_to_trace = [\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m     \u001b[43m_format_for_tracing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_list\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m message_list \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[32m    808\u001b[39m ]\n\u001b[32m    809\u001b[39m run_managers = callback_manager.on_chat_model_start(\n\u001b[32m    810\u001b[39m     \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m    811\u001b[39m     messages_to_trace,\n\u001b[32m   (...)\u001b[39m\u001b[32m    816\u001b[39m     batch_size=\u001b[38;5;28mlen\u001b[39m(messages),\n\u001b[32m    817\u001b[39m )\n\u001b[32m    818\u001b[39m results = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:115\u001b[39m, in \u001b[36m_format_for_tracing\u001b[39m\u001b[34m(messages)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages:\n\u001b[32m    114\u001b[39m     message_to_trace = message\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    116\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(message.content):\n\u001b[32m    117\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(block, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    118\u001b[39m                 \u001b[38;5;66;03m# Update image content blocks to OpenAI # Chat Completions format.\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "import os\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = \"sk-\"\n",
    "# 定义分类结果\n",
    "class CategoryOutput(BaseModel):\n",
    "    category: str = Field(description=\"问题分类: general 或 private\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=CategoryOutput)\n",
    "\n",
    "# 定义 Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"请将下面问题分类，输出 {format_instructions}。\\n\\n问题: {question}\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "llm = ChatDeepSeek(model=\"deepseek-chat\")\n",
    "\n",
    "question = \"公司内部流程该如何优化？\"\n",
    "_input = prompt.format_prompt(question=question)\n",
    "output = llm(_input.to_string())\n",
    "\n",
    "# LangChain 自动解析为 CategoryOutput 对象\n",
    "parsed = parser.parse(output.content)\n",
    "print(parsed.dict())\n",
    "# {\"category\": \"private\"}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
